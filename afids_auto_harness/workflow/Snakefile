from functools import partial
from pathlib import Path
import random

from snakebids import bids, generate_inputs


configfile: "config/config.yaml"


INPUT_DS_LABELS = ["hcp", "snsx", "oasis"]

t1w_inputs = partial(
    generate_inputs, pybids_inputs=config["pybids_inputs"], use_bids_inputs=True
)
afids_inputs = partial(
    generate_inputs, pybids_inputs=config["afids_inputs"], use_bids_inputs=True
)

inputs = {
    input_ds: {
        "afids": afids_inputs(
            bids_dir=Path(config[f"{input_ds}_dir"])
            / "derivatives"
            / "afids_groundtruth"
        ),
        "t1w": t1w_inputs(bids_dir=config[f"{input_ds}_dir"]),
    }
    for input_ds in INPUT_DS_LABELS
}


checkpoint split_inputs:
    input:
        **{
            f"{input_ds}_images": expand(
                inputs[input_ds]["t1w"]["t1w"].input_path,
                zip,
                **inputs[input_ds]["t1w"]["t1w"].input_zip_lists,
            )
            for input_ds in INPUT_DS_LABELS
        },
        **{
            f"{input_ds}_groundtruth": expand(
                bids(
                    root=Path(config[f"{input_ds}_dir"])
                    / "derivatives"
                    / "afids_groundtruth",
                    desc="groundtruth",
                    suffix="afids.fcsv",
                    space="T1w",
                    **inputs[input_ds]["t1w"]["t1w"].input_wildcards,
                ),
                zip,
                **inputs[input_ds]["t1w"]["t1w"].input_zip_lists,
            )
            for input_ds in INPUT_DS_LABELS
        },
    params:
        seed=config.get("seed", 0),
        train_proportion=config.get("train_proportion", 0.7),
    output:
        **{f"training_{input_ds}": directory(f"output/train/{input_ds}") for input_ds in INPUT_DS_LABELS},
        **{f"testing_{input_ds}": directory(f"output/test/{input_ds}") for input_ds in INPUT_DS_LABELS},
    script:
        "scripts/split_data.py"


rule merge_datasets:
    input:
        bids(root="output/train/hcp"


def subset_inputs(wildcards, output_name):
    split_output = checkpoints.split_inputs.get(**wildcards).output
    subset_dir = split_output[output_name]
    return generate_inputs(
        bids_dir=subset_dir, pybids_inputs=config["pybids_inputs"], use_bids_inputs=True
    )


def aggregate_input(wildcards, output_name):
    train_inputs = subset_inputs(wildcards, output_name)
    return expand(
        train_inputs["t1w"].input_path, zip, **train_inputs["t1w"].input_zip_lists
    )


rule train_model:
    input:
        training_data=partial(aggregate_input, output_name="training_data"),
    output:
        model=bids(
            root="output/models/auto-afids-train",
            suffix="model.rf",
            space="MNI152NLin2009cAsym",
        ),
    params:
        input_dir="output/train",
        model_dir="output/models",
    container:
        "docker://tristankk/afids-auto-train:latest"
    shell:
        "/opt/afids-auto-train/run.py {params.input_dir} {params.model_dir} participant --cores --force-output"


checkpoint apply_model:
    input:
        testing_data=partial(aggregate_input, output_name="testing_data"),
        model=rules.train_model.output["model"],
    params:
        model_dir="output/models",
        test_dir="output/test",
        out_dir="output/afids",
    output:
        out_dir=directory("output/afids/threshold_prob"),
    container:
        "docker://tristankk/afids-auto-apply:latest"
    resources:
        cores=workflow.cores,
    shell:
        "/opt/afids-auto-apply/run.py {params.test_dir} {params.out_dir} participant --model_dir {params.model_dir} --cores {resources.cores}"


def aggregate_fcsvs(wildcards):
    out_dir = checkpoints.apply_model.get(**wildcards).output["out_dir"]
    return bids(
        root=out_dir,
        datatype="anat",
        space="MNI152NLin2009cAsym",
        suffix="afids.fcsv",
        **inputs["t1w"].input_wildcards
    )


rule afle:
    input:
        ground_truth_fcsv=bids(
            root=str(Path("output") / "test" / "derivatives" / "afids_groundtruth"),
            desc="groundtruth",
            suffix="afids.fcsv",
            space="T1w",
            **inputs["hcp"]["t1w"]["t1w"].input_wildcards,
        ),
        model_fcsv=aggregate_fcsvs,
    output:
        afle=bids(
            root=str(Path("output") / "afles"),
            datatype="anat",
            suffix="afles.json",
            **inputs["hcp"]["t1w"]["t1w"].input_wildcards,
        ),
    script:
        "scripts/calc_afle.py"


def aggregate_all_inputs(wildcards):
    test_inputs = subset_inputs(wildcards, "testing_data")
    return expand(rules.afle.output["afle"], zip, **test_inputs["t1w"].input_zip_lists)


rule all:
    input:
        aggregate_all_inputs,
    default_target: True
