from functools import partial
from pathlib import Path
import random

from snakebids import bids, generate_inputs


configfile: "config/config.yaml"


inputs = generate_inputs(
    bids_dir=config["bids_dir"],
    pybids_inputs=config["pybids_inputs"],
    use_bids_inputs=True,
)


checkpoint split_inputs:
    input:
        input_images=expand(
            inputs["t1w"].input_path, zip, **inputs["t1w"].input_zip_lists
        ),
        ground_truth=expand(
            bids(
                root=str(
                    Path(config["bids_dir"]) / "derivatives" / "afids_groundtruth"
                ),
                desc="groundtruth",
                suffix="afids.fcsv",
                space="T1w",
                **inputs["t1w"].input_wildcards
            ),
            zip,
            **inputs["t1w"].input_zip_lists
        ),
    params:
        seed=config.get("seed", 0),
        train_proportion=config.get("train_proportion", 0.7),
    output:
        training_data=directory("output/train"),
        testing_data=directory("output/test"),
    script:
        "scripts/split_data.py"


def subset_inputs(wildcards, output_name):
    split_output = checkpoints.split_inputs.get(**wildcards).output
    subset_dir = split_output[output_name]
    return generate_inputs(
        bids_dir=subset_dir, pybids_inputs=config["pybids_inputs"], use_bids_inputs=True
    )


def aggregate_input(wildcards, output_name):
    train_inputs = subset_inputs(wildcards, output_name)
    return expand(
        train_inputs["t1w"].input_path, zip, **train_inputs["t1w"].input_zip_lists
    )


rule train_model:
    input:
        training_data=partial(aggregate_input, output_name="training_data"),
    output:
        model=bids(
            root="output/models/auto-afids-train",
            suffix="model.rf",
            space="MNI152NLin2009cAsym",
        ),
    params:
        input_dir="output/train",
        model_dir="output/models",
    container:
        "docker://tristankk/afids-auto-train:latest"
    shell:
        "/opt/afids-auto-train/run.py {params.input_dir} {params.model_dir} participant --cores --force-output"


checkpoint apply_model:
    input:
        testing_data=partial(aggregate_input, output_name="testing_data"),
        model=rules.train_model.output["model"],
    params:
        model_dir="output/models",
        test_dir="output/test",
        out_dir="output/afids",
    output:
        out_dir=directory("output/afids/threshold_prob"),
    container:
        "docker://tristankk/afids-auto-apply:latest"
    resources:
        cores=workflow.cores,
    shell:
        "/opt/afids-auto-apply/run.py {params.test_dir} {params.out_dir} participant --model_dir {params.model_dir} --cores {resources.cores}"


rule afle:
    input:
        ground_truth_fcsv=bids(
            root=str(Path("output") / "test" / "derivatives" / "afids_groundtruth"),
            desc="groundtruth",
            suffix="afids.fcsv",
            space="T1w",
            **inputs["t1w"].input_wildcards,
        ),
        model_fcsv=bids(
            root=str(Path("output") / "afids" / "threshold_prob"),
            datatype="anat",
            space="MNI152NLin2009cAsym",
            suffix="afids.fcsv",
            **inputs["t1w"].input_wildcards,
        ),
    output:
        afle=bids(
            root=str(Path("output") / "afles"),
            datatype="anat",
            suffix="afles.json",
            **inputs["t1w"].input_wildcards,
        ),
    script:
        "scripts/calc_afle.py"


def aggregate_all_inputs(wildcards):
    test_inputs = subset_inputs(wildcards, "testing_data")
    return expand(rules.afle.output["afle"], zip, **test_inputs["t1w"].input_zip_lists)


rule all:
    input:
        aggregate_all_inputs,
    default_target: True
