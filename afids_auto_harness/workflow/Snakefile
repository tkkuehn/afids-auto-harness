from functools import partial
from pathlib import Path
import random

from snakebids import bids, generate_inputs


configfile: "config/config.yaml"


wildcard_constraints:
    acq="[a-zA-Z\d]+",
    run="[a-zA-Z\d]+",
    subject="[a-zA-Z\d]+",
    session="[a-zA-Z\d]+",
    task="[a-zA-Z\d]+",


INPUT_DS_LABELS = ["hcp", "snsx", "oasis"]

t1w_inputs = partial(
    generate_inputs, pybids_inputs=config["pybids_inputs"], use_bids_inputs=True
)
afids_inputs = partial(
    generate_inputs, pybids_inputs=config["afids_inputs"], use_bids_inputs=True
)

inputs = {
    input_ds: {
        "afids": afids_inputs(
            bids_dir=Path(config[f"{input_ds}_dir"])
            / "derivatives"
            / "afids_groundtruth"
        ),
        "t1w": t1w_inputs(bids_dir=config[f"{input_ds}_dir"]),
    }
    for input_ds in INPUT_DS_LABELS
}


checkpoint split_inputs:
    input:
        **{
            f"{input_ds}_images": expand(
                inputs[input_ds]["t1w"]["t1w"].input_path,
                zip,
                **inputs[input_ds]["t1w"]["t1w"].input_zip_lists,
            )
            for input_ds in INPUT_DS_LABELS
        },
        **{
            f"{input_ds}_groundtruth": expand(
                bids(
                    root=Path(config[f"{input_ds}_dir"])
                    / "derivatives"
                    / "afids_groundtruth",
                    desc="groundtruth",
                    suffix="afids.fcsv",
                    space="T1w",
                    **inputs[input_ds]["t1w"]["t1w"].input_wildcards,
                ),
                zip,
                **inputs[input_ds]["t1w"]["t1w"].input_zip_lists,
            )
            for input_ds in INPUT_DS_LABELS
        },
    params:
        seed=config.get("seed", 0),
        train_proportion=config.get("train_proportion", 0.7),
    output:
        **{
            f"training_{input_ds}": directory(f"output/train/{input_ds}")
            for input_ds in INPUT_DS_LABELS
        },
        **{
            f"testing_{input_ds}": directory(f"output/test/{input_ds}")
            for input_ds in INPUT_DS_LABELS
        },
    script:
        "scripts/split_data.py"


rule merge_hcp:
    input:
        t1w=expand(
            bids(
                root="output/train/hcp",
                datatype="anat",
                suffix="T1w.nii.gz",
                **inputs["hcp"]["t1w"]["t1w"].input_wildcards
            ),
            acq=["MP2RAGE"],
            allow_missing=True,
        ),
        groundtruth=expand(
            bids(
                root=Path("output/train/hcp") / "derivatives" / "afids_groundtruth",
                desc="groundtruth",
                suffix="afids.fcsv",
                space="T1w",
                **inputs["hcp"]["t1w"]["t1w"].input_wildcards,
            ),
            acq=["MP2RAGE"],
            allow_missing=True,
        ),
    output:
        t1w=bids(
            root="output/merged",
            datatype="anat",
            suffix="T1w.nii.gz",
            **inputs["hcp"]["t1w"].subj_wildcards
        ),
        groundtruth=bids(
            root="output/merged/derivatives/afids_groundtruth",
            desc="groundtruth",
            suffix="afids.fcsv",
            space="T1w",
            **inputs["hcp"]["t1w"].subj_wildcards
        ),
    shell:
        "cp {input.t1w} {output.t1w} && "
        "cp {input.groundtruth} {output.groundtruth}"


rule merge_snsx:
    input:
        t1w=expand(
            bids(
                root="output/train/snsx",
                datatype="anat",
                suffix="T1w.nii.gz",
                **inputs["snsx"]["t1w"]["t1w"].input_wildcards
            ),
            acq=["MP2RAGE"],
            run=["01"],
            allow_missing=True,
        ),
        groundtruth=expand(
            bids(
                root=Path("output/train/snsx") / "derivatives" / "afids_groundtruth",
                desc="groundtruth",
                suffix="afids.fcsv",
                space="T1w",
                **inputs["snsx"]["t1w"]["t1w"].input_wildcards,
            ),
            acq=["MP2RAGE"],
            run=["01"],
            allow_missing=True,
        ),
    output:
        t1w=bids(
            root="output/merged",
            datatype="anat",
            suffix="T1w.nii.gz",
            **inputs["snsx"]["t1w"].subj_wildcards
        ),
        groundtruth=bids(
            root="output/merged/derivatives/afids_groundtruth",
            desc="groundtruth",
            suffix="afids.fcsv",
            space="T1w",
            **inputs["snsx"]["t1w"].subj_wildcards
        ),
    shell:
        "cp {input.t1w} {output.t1w} && "
        "cp {input.groundtruth} {output.groundtruth}"


rule merge_oasis:
    input:
        t1w=bids(
            root="output/train/oasis",
            datatype="anat",
            suffix="T1w.nii.gz",
            **inputs["oasis"]["t1w"]["t1w"].input_wildcards
        ),
        groundtruth=bids(
            root=Path("output/train/oasis") / "derivatives" / "afids_groundtruth",
            desc="groundtruth",
            suffix="afids.fcsv",
            space="T1w",
            **inputs["oasis"]["t1w"]["t1w"].input_wildcards,
        ),
    output:
        t1w=bids(
            root="output/merged",
            datatype="anat",
            suffix="T1w.nii.gz",
            **inputs["oasis"]["t1w"].subj_wildcards
        ),
        groundtruth=bids(
            root="output/merged/derivatives/afids_groundtruth",
            desc="groundtruth",
            suffix="afids.fcsv",
            space="T1w",
            **inputs["oasis"]["t1w"].subj_wildcards
        ),
    shell:
        "cp {input.t1w} {output.t1w} && "
        "cp {input.groundtruth} {output.groundtruth}"


def aggregate_training(wildcards):
    split_output = checkpoints.split_inputs.get(**wildcards).output
    subjects = []
    for in_ds in INPUT_DS_LABELS:
        subset_dir = split_output[f"training_{in_ds}"]
        subset_inputs = generate_inputs(
            bids_dir=subset_dir,
            pybids_inputs=config["pybids_inputs"],
            use_bids_inputs=True,
        )
        subjects.extend(subset_inputs["t1w"].input_zip_lists["subject"])
    return {
        "groundtruth": expand(
            bids(
                root="output/merged/derivatives/afids_groundtruth",
                desc="groundtruth",
                suffix="afids.fcsv",
                space="T1w",
                subject="{subject}",
            ),
            subject=subjects,
        ),
        "t1w": expand(
            bids(
                root="output/merged",
                datatype="anat",
                suffix="T1w.nii.gz",
                subject="{subject}",
            ),
            subject=subjects,
        ),
    }


rule write_config:
    params:
        patchsize="    patch: {patchsize}",
        ntrees="    ntrees: {ntrees}",
        treedepth="    treedepth: {treedepth}",
        usexyz="    usexyz: {usexyz}",
        spheresize="    sphere_size: {spheresize}",
    output:
        configfile="output/config/patchsize-{patchsize}_ntrees-{ntrees}_treedepth-{treedepth}_usexyz-{usexyz}_spheresize-{spheresize}_config.yml",
    shell:
        'echo "c3d:" > {output} && '
        'echo "  model_params:" >> {output} && '
        'echo "{params.patchsize}" >> {output} && '
        'echo "{params.ntrees}" >> {output} && '
        'echo "{params.treedepth}" >> {output} && '
        'echo "{params.usexyz}" >> {output} && '
        'echo "  landmarks:" >> {output} && '
        'echo "{params.spheresize}" >> {output}'


rule train_model:
    input:
        unpack(aggregate_training),
        configfile=rules.write_config.output.configfile,
    output:
        model=bids(
            root="output/models/patchsize-{patchsize}_ntrees-{ntrees}_treedepth-{treedepth}_usexyz-{usexyz}_spheresize-{spheresize}/auto-afids-train",
            suffix="patchsize-{patchsize}_ntrees-{ntrees}_treedepth-{treedepth}_usexyz-{usexyz}_spheresize-{spheresize}_model.rf",
            space="MNI152NLin2009cAsym",
        ),
    params:
        input_dir="output/merged",
        model_dir="output/models/patchsize-{patchsize}_ntrees-{ntrees}_treedepth-{treedepth}_usexyz-{usexyz}_spheresize-{spheresize}",
    container:
        "docker://tristankk/afids-auto-train:latest"
    shell:
        "/opt/afids-auto-train/run.py {params.input_dir} {params.model_dir} participant --cores --force-output --configfile {input.configfile}"


def subset_inputs(wildcards, output_name):
    split_output = checkpoints.split_inputs.get(**wildcards).output
    subset_dir = split_output[output_name]
    return generate_inputs(
        bids_dir=subset_dir, pybids_inputs=config["pybids_inputs"], use_bids_inputs=True
    )


def aggregate_testing(wildcards):
    output_name = f"testing_{wildcards['ds']}"
    train_inputs = subset_inputs(wildcards, output_name)
    return expand(
        train_inputs["t1w"].input_path, zip, **train_inputs["t1w"].input_zip_lists
    )


checkpoint apply_model:
    input:
        testing_data=aggregate_testing,
        model=rules.train_model.output["model"],
    params:
        model_dir="output/models/patchsize-{patchsize}_ntrees-{ntrees}_treedepth-{treedepth}_usexyz-{usexyz}_spheresize-{spheresize}",
        test_dir="output/test/{ds}",
        out_dir="output/afids/patchsize-{patchsize}_ntrees-{ntrees}_treedepth-{treedepth}_usexyz-{usexyz}_spheresize-{spheresize}/{ds}",
    output:
        out_dir=directory(
            "output/afids/patchsize-{patchsize}_ntrees-{ntrees}_treedepth-{treedepth}_usexyz-{usexyz}_spheresize-{spheresize}/{ds}/threshold_prob"
        ),
    container:
        "docker://tristankk/afids-auto-apply:latest"
    resources:
        cores=workflow.cores,
    shell:
        "/opt/afids-auto-apply/run.py {params.test_dir} {params.out_dir} participant --model_dir {params.model_dir} --cores {resources.cores}"


def aggregate_fcsvs(wildcards):
    out_dir = checkpoints.apply_model.get(**wildcards).output["out_dir"]
    return bids(
        root=out_dir,
        datatype="anat",
        space="MNI152NLin2009cAsym",
        suffix="afids.fcsv",
        **inputs[wildcards["ds"]]["t1w"]["t1w"].input_wildcards
    )


rule afle_hcp:
    input:
        ground_truth_fcsv=bids(
            root=str(
                Path("output") / "test" / "{ds}" / "derivatives" / "afids_groundtruth"
            ),
            desc="groundtruth",
            suffix="afids.fcsv",
            space="T1w",
            **inputs["hcp"]["t1w"]["t1w"].input_wildcards,
        ),
        model_fcsv=aggregate_fcsvs,
    output:
        afle=bids(
            root=str(
                Path("output")
                / "afles"
                / "patchsize-{patchsize}_ntrees-{ntrees}_treedepth-{treedepth}_usexyz-{usexyz}_spheresize-{spheresize}"
                / "{ds}"
            ),
            datatype="anat",
            suffix="afles.json",
            **inputs["hcp"]["t1w"]["t1w"].input_wildcards,
        ),
    script:
        "scripts/calc_afle.py"


rule afle_snsx:
    input:
        ground_truth_fcsv=bids(
            root=str(
                Path("output") / "test" / "{ds}" / "derivatives" / "afids_groundtruth"
            ),
            desc="groundtruth",
            suffix="afids.fcsv",
            space="T1w",
            **inputs["snsx"]["t1w"]["t1w"].input_wildcards,
        ),
        model_fcsv=aggregate_fcsvs,
    output:
        afle=bids(
            root=str(
                Path("output")
                / "afles"
                / "patchsize-{patchsize}_ntrees-{ntrees}_treedepth-{treedepth}_usexyz-{usexyz}_spheresize-{spheresize}"
                / "{ds}"
            ),
            datatype="anat",
            suffix="afles.json",
            **inputs["snsx"]["t1w"]["t1w"].input_wildcards,
        ),
    script:
        "scripts/calc_afle.py"


rule afle_oasis:
    input:
        ground_truth_fcsv=bids(
            root=str(
                Path("output") / "test" / "{ds}" / "derivatives" / "afids_groundtruth"
            ),
            desc="groundtruth",
            suffix="afids.fcsv",
            space="T1w",
            **inputs["oasis"]["t1w"]["t1w"].input_wildcards,
        ),
        model_fcsv=aggregate_fcsvs,
    output:
        afle=bids(
            root=str(
                Path("output")
                / "afles"
                / "patchsize-{patchsize}_ntrees-{ntrees}_treedepth-{treedepth}_usexyz-{usexyz}_spheresize-{spheresize}"
                / "{ds}"
            ),
            datatype="anat",
            suffix="afles.json",
            **inputs["oasis"]["t1w"]["t1w"].input_wildcards,
        ),
    script:
        "scripts/calc_afle.py"


def aggregate_all_inputs(wildcards):
    return (
        expand(
            expand(
                rules.afle_hcp.output["afle"],
                ds="hcp",
                patchsize=config["patch_size"],
                ntrees=config["ntrees"],
                treedepth=config["treedepth"],
                usexyz=config["usexyz"],
                spheresize=config["spheresize"],
                allow_missing=True,
            ),
            zip,
            **subset_inputs(wildcards, "testing_hcp")["t1w"].input_zip_lists
        )
        + expand(
            expand(
                rules.afle_snsx.output["afle"],
                ds="snsx",
                patchsize=config["patch_size"],
                ntrees=config["ntrees"],
                treedepth=config["treedepth"],
                usexyz=config["usexyz"],
                spheresize=config["spheresize"],
                allow_missing=True,
            ),
            zip,
            **subset_inputs(wildcards, "testing_snsx")["t1w"].input_zip_lists
        )
        + expand(
            expand(
                rules.afle_oasis.output["afle"],
                ds="oasis",
                patchsize=config["patch_size"],
                ntrees=config["ntrees"],
                treedepth=config["treedepth"],
                usexyz=config["usexyz"],
                spheresize=config["spheresize"],
                allow_missing=True,
            ),
            zip,
            **subset_inputs(wildcards, "testing_oasis")["t1w"].input_zip_lists
        )
    )


rule all:
    input:
        aggregate_all_inputs,
    default_target: True
